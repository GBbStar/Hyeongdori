## 인공신경망   

### CNN의 네트워크 종류   

***

   

### 1. LeNet   

* 손글씨 숫자를 인식하는 네트워크

* 합성곱 계층과 풀링 계층을 반복, 마지막으로 완전연결 계층을 거치면서 결과를 출력

* 시그모이드 사용, 서브 샘플링으로 중간 데이터의 크기가 작아진다.

  **시그모이드(Sigmoid) 함수** : Binary Classification에 적절한 함수

  * 일정 값을 기준으로 0과 1로 구분하여 분류하는 방식
  * 딥러닝에서 특정 임계치를 초과할 때만 활성화 된다.
  * Activation Function 중의 하나로 구분되는 함수

   

### 2. AlexNet

* 합성곱 계층과 풀링 계층을 거듭하며 마지막으로 완전연결 계층을 거쳐 결과를 출력

* 활성화 함수로 ReLU를 사용

  **ReLU 함수** : Hidden layer를 활성화 시키는 함수

  * 시그모이드 함수를 사용하지 않는다.
  * 0보다 작은 값이 나오면 0, 큰 값이 나오면 그대로 반환하는 함수
  * 내부 **hidden layer**에는 **ReLU**를 적용, 마지막 **output layer**에서만 **Sigmoid 함수** 적용시<br> 이전에 비해 정확도가 훨씬 상승함

* LRN이라는 국소적 정규화를 실시하는 계층 이용

* 드롭아웃을 사용한다.

   

### 3. VGGNet

* 합성곱 계층과 풀링 계층으로 구성되는 기본적인 CNN
* 비중있는 층인 **합성곱 계층**, **완전연결 계층**을 모두 16개, 혹은 19개로 심화한 특징을 가짐
* 층의 깊이에 따라 VGG16, VGG19로 구분한다.
* 3 by 3 matrix 필터를 사용한 **합성곱 계층**을 연속적으로 거친다.
* **합성곱 계층**을 2~4회 연속으로 풀링 계층을 두어 크기를 절반으로 줄이는 처리를 반복한다.
* 마지막에 **완전연결 계층**을 통과시켜 결과를 출력한다.

   

### 4. GoogleNet

* 깊이(세로) 뿐만 아니라 폭(가로)도 깊은 특징을 가지고 있다.

* 인셉션 구조를 하나의 빌딩 블록으로 사용한다.

  **인셉션 구조**

  * 크기가 다른 필터와 풀링을 여러 개 적용하여 그 결과를 결합한다.

* 1 by 1 matrix 크기의 필터를 사용한 합성곱 계층을 많은 곳에서 사용한다.

  * 1 by 1 합성곱 연산은 채널 쪽 크기를 줄이는 것
  * 매개변수 제거와 고속 처리에 기여한다.

   

### 5. ResNet

* 보다 더 층을 깊게 쌓기 위해 **스킵 연결**을 도입한다.

  **스킵 연결**

  * 입력 데이터를 합성곱 계층을 건너뛰어 출력에 바로 더하는 구조

  * 역전파 시 스킵 연결이 신호 감쇠를 막아주어 층이 깊어져도 <br>학습을 효율적으로 할 수 있도록 해줌

    