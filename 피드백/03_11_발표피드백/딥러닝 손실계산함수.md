```python
# Directories
    wdir = save_dir / 'weights'
    wdir.mkdir(parents=True, exist_ok=True)  # make dir
    last = wdir / 'last.pt'
    best = wdir / 'best.pt'
    results_file = save_dir / 'results.txt'
```


      File "<ipython-input-2-3f3be0700e9c>", line 2
        wdir = save_dir / 'weights'
        ^
    IndentationError: unexpected indent
    



```python
 # Configure
    plots = not opt.evolve  # create plots
    cuda = device.type != 'cpu'
    init_seeds(2 + rank)
    with open(opt.data) as f:
        data_dict = yaml.load(f, Loader=yaml.SafeLoader)  # data dict
    with torch_distributed_zero_first(rank):
        check_dataset(data_dict)  # check
    train_path = data_dict['train']
    test_path = data_dict['val']
    nc = 1 if opt.single_cls else int(data_dict['nc'])  # number of classes
    names = ['item'] if opt.single_cls and len(data_dict['names']) != 1 else data_dict['names']  # class names
    assert len(names) == nc, '%g names found for nc=%g dataset in %s' % (len(names), nc, opt.data)  # check
# 데이터 불러오기
```


      File "<ipython-input-3-34a544c8d2f4>", line 2
        plots = not opt.evolve  # create plots
        ^
    IndentationError: unexpected indent
    



```python
# Model
    pretrained = weights.endswith('.pt')
    if pretrained:
        with torch_distributed_zero_first(rank):
            attempt_download(weights)  # download if not found locally
            
            # torch.load() : pickle을 사용해서 저장된 객체 파일들을 역직렬화, 메모리에 올림
            # 데이터를 장치에 불러올 때도 사용한다.
            # GPU에서 학습한 모델을 CPU에서 불러올 때 torch.load() 함수의 map_location인자에 device를 전달
            # device는 ln[3] 코드 부분에 2번째 줄에 cpu로 설정되어 있음 
        ckpt = torch.load(weights, map_location=device)  # load checkpoint
        model = Model(opt.cfg or ckpt['model'].yaml, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)  # create
        exclude = ['anchor'] if (opt.cfg or hyp.get('anchors')) and not opt.resume else []  # exclude keys
        state_dict = ckpt['model'].float().state_dict()  # to FP32
        state_dict = intersect_dicts(state_dict, model.state_dict(), exclude=exclude)  # intersect
        
        # load_state_dict() : 역직렬화된 state_dict을 사용해서 모델의 매개변수들을 불러온다
        model.load_state_dict(state_dict, strict=False)  # load
        logger.info('Transferred %g/%g items from %s' % (len(state_dict), len(model.state_dict()), weights))  # report
    else:
        model = Model(opt.cfg, ch=3, nc=nc, anchors=hyp.get('anchors')).to(device)  # create
# 모델만들기
```


      File "<ipython-input-4-516fbb80ea83>", line 2
        pretrained = weights.endswith('.pt')
        ^
    IndentationError: unexpected indent
    



```python
 # 
    dataloader, dataset = create_dataloader(train_path, imgsz, batch_size, gs, opt,
                                            hyp=hyp, augment=True, cache=opt.cache_images, rect=opt.rect, rank=rank,
                                            world_size=opt.world_size, workers=opt.workers,
                                            image_weights=opt.image_weights, quad=opt.quad, prefix=colorstr('train: '))
    mlc = np.concatenate(dataset.labels, 0)[:, 0].max()  # max label class
    nb = len(dataloader)  # number of batches
    assert mlc < nc, 'Label class %g exceeds nc=%g in %s. Possible class labels are 0-%g' % (mlc, nc, opt.data, nc - 1)

    # Process 0
    if rank in [-1, 0]:
        testloader = create_dataloader(test_path, imgsz_test, batch_size * 2, gs, opt,  # testloader
                                       hyp=hyp, cache=opt.cache_images and not opt.notest, rect=True, rank=-1,
                                       world_size=opt.world_size, workers=opt.workers,
                                       pad=0.5, prefix=colorstr('val: '))[0]

        if not opt.resume:
            labels = np.concatenate(dataset.labels, 0)
            c = torch.tensor(labels[:, 0])  # classes
            # cf = torch.bincount(c.long(), minlength=nc) + 1.  # frequency
            # model._initialize_biases(cf.to(device))
            if plots:
                plot_labels(labels, save_dir, loggers)
                if tb_writer:
                    tb_writer.add_histogram('classes', c, 0)

            # Anchors
            if not opt.noautoanchor:
                check_anchors(dataset, model=model, thr=hyp['anchor_t'], imgsz=imgsz)
            model.half().float()  # pre-reduce anchor precision
```


      File "<ipython-input-5-8ebab56f2f3d>", line 2
        dataloader, dataset = create_dataloader(train_path, imgsz, batch_size, gs, opt,
        ^
    IndentationError: unexpected indent
    



```python
# Forward
            with amp.autocast(enabled=cuda):
                pred = model(imgs)  # forward
            # compute_loss : 손실 계산 함수 
            # 평균 제곱 오차 
                loss, loss_items = compute_loss(pred, targets.to(device))  # loss scaled by batch_size
                if rank != -1:
                    loss *= opt.world_size  # gradient averaged between devices in DDP mode
                if opt.quad:
                    loss *= 4.

            # Backward
            scaler.scale(loss).backward()
            
# 각 거리 차이를 제곱하여 합산한 후에 평균을 낸다.
# (i+1) : 전체 데이터의 수
# E = 1/전체 데이터의 수 * (for(k=0; k<전체 데이터의 수; k++) {(k번째 y - k번째 t)^2})
mloss = (mloss * i + loss_items) / (i + 1)  # update mean losses
```


      File "<ipython-input-6-eae36dd18627>", line 2
        with amp.autocast(enabled=cuda):
        ^
    IndentationError: unexpected indent
    



```python
# 손실 계산 함수 내부 
# 평균 제곱 오차 : 모델의 출력값과 사용자가 원하는 출력 값 사이의 거리 차이를 오차로 사용

def compute_loss(self, weights):
        num_classes = weights.size(0)
        cos = torch.mm(weights, weights.t())
        if not self.normalize_weights:
            norms = self.weight_norms.unsqueeze(1)
            cos = cos / (norms*norms.t())

        cos1 = cos.clone()
        with torch.no_grad():
            row_nums = torch.arange(num_classes).long().to(weights.device)
            cos1[row_nums, row_nums] = -float('inf')
            _, indices = torch.max(cos1, dim=1)
            mask = torch.zeros((num_classes, num_classes)).to(weights.device)
            mask[row_nums, indices] = 1
        
        return {"loss": {"losses": torch.sum(cos*mask, dim=1), "indices": c_f.torch_arange_from_size(weights), "reduction_type": "element"}} 
```
